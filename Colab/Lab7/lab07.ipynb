{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7: Predicting Voter Turnout\n",
    "\n",
    "Welcome to Lab 7! This week, we will be constructing models to predict voter turnout. We will be using the same dataset as last week's lab (note that I removed `treat`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/joshuakalla/data_science_campaigns/master/Colab/Lab7/gerber_huber_2014_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is a classification algorithm that is used to predict the probability of a categorical dependent variable. In logistic regression, the dependent variable is a binary variable that contains data coded as 1 (voted, yes, success, etc.) or 0 (did not vote, no, failure, etc.). In other words, the logistic regression model predicts P(Y=1) (probability that a person voted) as a function of X (many different covariates).\n",
    "\n",
    "(You could use other algorithms to build a model. We are using logistic regression because it is fast and easy.)\n",
    "\n",
    "Our goal is to predict whether an individual voter *i* voted in the 2014 election as a function of other features we know about them (age, past vote history, race, and gender). With a model of voting in the 2014 election, a campaign in the future (such as in 2018) could better target voters.\n",
    "\n",
    "To get started, let's see if there are any big differences in who votes in 2014. Run the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('voted14').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** What do you find? Do any individual variables seem to be more or less predictive of voting in 2014? Interpret the above table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer the question here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to build a simple model. We first need to define our outcome variable (did someone vote in 2014 or not, call this *Y*) and our set of predictor variables (call this a matrix *X*). In this first simple case, we will only include `voted12` and `age` in X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['voted12', 'age', 'intercept']\n",
    "data['intercept'] = 1 # add a column of 1's for the intercept term\n",
    "X = data[cols]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['voted14']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now build our model. Note that we are now using a new module in Python called `statsmodels`. You can learn more about this module [here](https://www.statsmodels.org/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "## ignore the warning; nothing to worry about\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** Can you interpret this output? What do you think this means? (You might want to give [this](https://www.juanshishido.com/logisticcoefficients.html) a read.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer the question here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the below code, we can construct model scores. Remember that the output of this can be understood as the probability that someone votes in 2014 as a function of their age and whether they voted in 2012."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = result.predict(X)\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** Make a plot showing the relationship between your predicted model (`y_pred`) and whether someone actually voted in 2014. In text, make sure you interpret this plot.\n",
    "\n",
    "*Hint.* You will probably want to use the [Pandas.cut() method](https://www.geeksforgeeks.org/pandas-cut-method-in-python/). This will allow you to create bins of `y_pred`. Remember the figures we discussed in the Likely Voter slides. You probably want to make a similar plot to this, like the below figure. (You don't need to exactly copy this, just an example of what you could do.) **This is a challenging question.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](sample_plot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert plot and interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To more formally assess this model, let's make a 2x2 confusion matrix, like we did in class. The confusion matrix needs to have 4 cells: number of true positives, number of true negatives, number of false positives, number of false negatives. (If you want a reminder on a confusion matrix, see the slides from lecture or read [this](https://www.python-course.eu/confusion_matrix.php).)\n",
    "\n",
    "For this exercise, we are going to define our threshold as 0.5. That means that if someone's predicted turnout (`y_pred`) is greater than 0.5, we are going to say that we predicted they vote. If their score is less than or equal to 0.5, we are going to say we predicted they did not vote. (Note that this threshold is somewhat arbitrary. We could define different cut-offs.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** Make the confusion matrix. Calculate the number of true positives, number of true negatives, number of false positives, number of false negatives. Fill in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the below table with the correct numbers.\n",
    "\n",
    "- Actual Negative and Predicted Negative (what do we call this?):\n",
    "- Actual Negative and Predicted Positive (what do we call this?):\n",
    "- Actual Positive and Predicted Negative (what do we call this?):\n",
    "- Actual Positive and Predicted Positive (what do we call this?):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.** Based on this table, calculate the model's accuracy, precision, and recall. Interpret this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put your interpretation here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6.** Can a different model do better? It is now your turn to build a model from scratch. Follow the same steps as above. Select your predictor variables. Build your model. Construct a confusion matrix. Calculate accuracy, precision, and recall. How does this model do? Does it do better or worse than the original model? Would you use it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Put your interpretation here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.** Find a way to plot the differences between the two models we built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are we overfitting?\n",
    "\n",
    "If you don't remember what overfitting means, review your notes from class or give this a read: https://www.ibm.com/topics/overfitting\n",
    "\n",
    "Let's see how these models do out-of-sample. Are we overfitting?\n",
    "\n",
    "To test this, you will need to run your model on a new data set (test set). You can then assess the confusion matrix and accuracy/precision/recall of your model on that test set.\n",
    "\n",
    "Note that a logistic regression is written as:\n",
    "\n",
    "$p(x) = \\frac{1}{1+e^{-(\\beta_0 + \\beta_1 x)}}$, where $e$ is Euler's number, approximately 2.71828. You can get Euler's number in Python using `np.exp()`.\n",
    "\n",
    "We will need to manually re-create this logistic regression. From my model, the coefficients are:\n",
    "\n",
    "- voted12: 2.1814\n",
    "- age: 0.0145\n",
    "- intercept: -2.7879\n",
    "\n",
    "We could therefore recreate our logistic regression by calculating:\n",
    "\n",
    "$p(voted14) = \\frac{1}{1+e^{-(-2.7879 + 0.0145*age + 2.1814*voted12)}}$\n",
    "\n",
    "Let's see this in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate y_pred by hand; call it y_pred2\n",
    "y_pred2 = 1/(1+np.exp(-(-2.787942 + 2.181396 *X[\"voted12\"] + .0145461 * X[\"age\"])))\n",
    "\n",
    "# Confirm that y_pred is the same as y_pred2\n",
    "y_preds = pd.concat([pd.DataFrame(y_pred), pd.DataFrame(y_pred2)], axis = 1)\n",
    "y_preds.columns = ['y_pred', 'y_pred2']\n",
    "y_preds['diff'] = abs(y_preds['y_pred']) - y_preds['y_pred2']\n",
    "\n",
    "# Print out this data frame\n",
    "print(y_preds.head())\n",
    "print(y_preds[\"diff\"].mean()) # Small differences due to rounding, but this is essentially a 0\n",
    "# These columns are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now want you to test if your model is over-fit. Don't cheat by recreating your model. Just use what you have above. I care about the process, not the actual performance.\n",
    "\n",
    "The data you used above came from South Dakota. I want you to see how the model performs in Wisconsin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"https://raw.githubusercontent.com/joshuakalla/data_science_campaigns/master/Colab/Lab7/test_data.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8.** Evaluate how your model performs out-of-sample using `test_data.csv` and the coefficients from your model. Create a confusion matrix and calculate the accuracy/precision/recall. How does your model perform out-of-sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "You are done with the lab. Before you finish and submit, please fill out this brief evaluation:\n",
    "\n",
    "- I spent around XXXX hours on this lab,.\n",
    "- This lab was (too easy, too hard, just about the right difficulty).\n",
    "\n",
    "**To turn in your lab, you will need to submit a PDF through Canvas.**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
